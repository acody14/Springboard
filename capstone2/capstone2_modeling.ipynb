{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4a1fde-e01a-46b1-a9ab-a4c2607306f0",
   "metadata": {},
   "source": [
    "# Capstone 2 Modeling\n",
    "## NBA Salary Predictor and Trade Suggestion\n",
    "## Austin Cody\n",
    "#### Models to attempt: Lasso Regression, Random Forest Regressor, XGBoost\n",
    "#### Tuning techniques: GridsearchCV, Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b491875f-4ca7-4a0a-8add-5fcb198f370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a9f4b6-a9c8-450e-8cfa-eb76b6aa50e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test,y_pred):\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f'Mean Squared Error: {rmse}')\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52dbbe31-72a1-4c8c-8ab6-f1f8bdc1d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in csv, splitting data into train/test\n",
    "df = pd.read_csv('nba_salaries_dummies.csv')\n",
    "features = ['age','2_pointers_pg','3_pointers_pg','free_throws_pg','assists_pg','points_pg', 'minutes_pg']\n",
    "\n",
    "X = df[features].values\n",
    "y = df['salary'].values\n",
    "\n",
    "# We will do optimization and kfold cross validation on the training set and we don't even touch our test set until the final eval\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec0412bd-92a6-47c5-9785-cdd4d7a50573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling from previous notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b28f8e-22d5-4f79-9313-b3fcc442bfb0",
   "metadata": {},
   "source": [
    "## Linear Regression using Lasso Regularization and hyperparameter tuning using RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d581c5e4-2f3e-46c2-941f-5272a35138e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "lasso = Lasso(max_iter=100000)\n",
    "lasso_gscv = GridSearchCV(lasso, param_grid=params, cv=5, scoring='r2')\n",
    "lasso_gscv.fit(X_train_scaled,y_train)\n",
    "\n",
    "best_alpha = lasso_gscv.best_params_\n",
    "\n",
    "best_lasso = Lasso(alpha=best_alpha['alpha'], max_iter=100000)\n",
    "best_lasso.fit(X_train_scaled, y_train)\n",
    "y_pred = best_lasso.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6cec502-1b4a-4bf1-8e48-e1030fdea2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Parameters for Lasso Regression\n",
      "Mean Squared Error: 6412006.254384973\n",
      "Mean Absolute Error: 4609206.600191674\n",
      "R-squared: 0.7155166799046566\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal Parameters for Lasso Regression\")\n",
    "print_metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162984f8-9786-47aa-84f1-18e4ee60ca31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.603088943001665"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross validation using the optimized random forest regressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "cv_results = cross_val_score(best_lasso, X, y, cv=kf, scoring='r2')\n",
    "np.mean(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3104d62-1e41-40a3-9634-328cb9f8d811",
   "metadata": {},
   "source": [
    "## Random Forest Regressor Bayesian Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5b157b-8585-4fd0-a43d-ae0c2b02bd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | max_le... | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.6721   \u001b[0m | \u001b[0m7.512    \u001b[0m | \u001b[0m4.365    \u001b[0m | \u001b[0m14.59    \u001b[0m | \u001b[0m2.062    \u001b[0m | \u001b[0m9.264    \u001b[0m | \u001b[0m173.3    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.5597   \u001b[0m | \u001b[0m2.798    \u001b[0m | \u001b[0m3.882    \u001b[0m | \u001b[0m31.09    \u001b[0m | \u001b[0m2.266    \u001b[0m | \u001b[0m7.336    \u001b[0m | \u001b[0m36.38    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.3554   \u001b[0m | \u001b[0m7.109    \u001b[0m | \u001b[0m4.445    \u001b[0m | \u001b[0m2.041    \u001b[0m | \u001b[0m5.362    \u001b[0m | \u001b[0m7.698    \u001b[0m | \u001b[0m101.4    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.6068   \u001b[0m | \u001b[0m16.22    \u001b[0m | \u001b[0m3.157    \u001b[0m | \u001b[0m41.76    \u001b[0m | \u001b[0m9.881    \u001b[0m | \u001b[0m8.475    \u001b[0m | \u001b[0m34.33    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.6417   \u001b[0m | \u001b[0m13.97    \u001b[0m | \u001b[0m4.861    \u001b[0m | \u001b[0m8.185    \u001b[0m | \u001b[0m8.006    \u001b[0m | \u001b[0m4.285    \u001b[0m | \u001b[0m199.0    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.6341   \u001b[0m | \u001b[0m17.63    \u001b[0m | \u001b[0m4.512    \u001b[0m | \u001b[0m32.23    \u001b[0m | \u001b[0m3.723    \u001b[0m | \u001b[0m9.273    \u001b[0m | \u001b[0m132.3    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.6406   \u001b[0m | \u001b[0m14.63    \u001b[0m | \u001b[0m3.908    \u001b[0m | \u001b[0m7.577    \u001b[0m | \u001b[0m7.023    \u001b[0m | \u001b[0m6.131    \u001b[0m | \u001b[0m198.5    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.5631   \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m172.0    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.3924   \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m160.6    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.4116   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m4.268    \u001b[0m | \u001b[0m20.61    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m188.0    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.6495   \u001b[0m | \u001b[0m4.128    \u001b[0m | \u001b[0m6.679    \u001b[0m | \u001b[0m18.39    \u001b[0m | \u001b[0m2.231    \u001b[0m | \u001b[0m6.537    \u001b[0m | \u001b[0m165.7    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.6708   \u001b[0m | \u001b[0m14.64    \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m22.25    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m168.5    \u001b[0m |\n",
      "| \u001b[95m13       \u001b[0m | \u001b[95m0.6775   \u001b[0m | \u001b[95m12.04    \u001b[0m | \u001b[95m3.0      \u001b[0m | \u001b[95m29.81    \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m153.4    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.3907   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m34.19    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m143.6    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.6277   \u001b[0m | \u001b[0m13.0     \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m27.67    \u001b[0m | \u001b[0m9.168    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m161.1    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.6632   \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m28.18    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m2.939    \u001b[0m | \u001b[0m156.7    \u001b[0m |\n",
      "| \u001b[95m17       \u001b[0m | \u001b[95m0.6941   \u001b[0m | \u001b[95m20.0     \u001b[0m | \u001b[95m3.0      \u001b[0m | \u001b[95m39.02    \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m156.7    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.5711   \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m35.26    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m147.4    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.6694   \u001b[0m | \u001b[0m11.72    \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m36.17    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m4.355    \u001b[0m | \u001b[0m164.4    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.673    \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m40.8     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m7.449    \u001b[0m | \u001b[0m116.3    \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "#optimizes r2 for our random forest regressor\n",
    "def rfr_objective_function(n_estimators,max_depth,min_samples_split,min_samples_leaf,max_features,max_leaf_nodes):\n",
    "    rfr = RandomForestRegressor(n_estimators=int(n_estimators),\n",
    "                                max_depth=int(max_depth),\n",
    "                                min_samples_split=int(min_samples_split),\n",
    "                                min_samples_leaf=int(min_samples_leaf),\n",
    "                                max_features=int(max_features),\n",
    "                                max_leaf_nodes=int(max_leaf_nodes))\n",
    "\n",
    "    # cross validating inside our objective functions avoids overfitting to our individual set of data\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    cv_scores = cross_val_score(rfr, X_train_scaled, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "rfr_bo = BayesianOptimization(f = rfr_objective_function,\n",
    "                                pbounds = {'n_estimators':(10,200),\n",
    "                                           'max_depth':(1,20),\n",
    "                                           'min_samples_split':(2,10),\n",
    "                                           'min_samples_leaf':(1,10),\n",
    "                                           'max_features':(3,len(features)),\n",
    "                                           'max_leaf_nodes':(2,50)})\n",
    "\n",
    "rfr_bo.maximize(n_iter=15, init_points=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "711c282e-db0c-4ee2-a173-3a6136922c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Parameters for Random Forest Regressor\n",
      "max_depth: 20.0\n",
      "max_features: 3.0\n",
      "max_leaf_nodes: 39.02008696395414\n",
      "min_samples_leaf: 1.0\n",
      "min_samples_split: 10.0\n",
      "n_estimators: 156.66834376080791\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal Parameters for Random Forest Regressor\")\n",
    "for key, value in rfr_bo.max['params'].items():\n",
    "    print(\"{}: {}\".format(key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46785f4b-e40d-4a50-bed0-a274f190cbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Optimized Random Forest Regressor:\n",
      "Mean Squared Error: 6165325.348730452\n",
      "Mean Absolute Error: 4068783.5999314766\n",
      "R-squared: 0.7369847487188208\n"
     ]
    }
   ],
   "source": [
    "rfr_optimized = RandomForestRegressor(max_depth = int(rfr_bo.max['params']['max_depth']),\n",
    "                                      max_features = int(rfr_bo.max['params']['max_features']),\n",
    "                                      max_leaf_nodes = int(rfr_bo.max['params']['max_leaf_nodes']),\n",
    "                                      min_samples_leaf = int(rfr_bo.max['params']['min_samples_leaf']),\n",
    "                                      min_samples_split = int(rfr_bo.max['params']['min_samples_split']),\n",
    "                                      n_estimators = int(rfr_bo.max['params']['n_estimators']))\n",
    "rfr_optimized.fit(X_train_scaled,y_train)\n",
    "y_pred = rfr_optimized.predict(X_test_scaled)\n",
    "\n",
    "print('Bayesian Optimized Random Forest Regressor:')\n",
    "print_metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41b18de5-7b40-472f-accd-91339b6137de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218020154618174"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross validation using the optimized random forest regressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "cv_results = cross_val_score(rfr_optimized, X, y, cv=kf, scoring='r2')\n",
    "np.mean(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7727b8b5-a49f-448b-9c86-76c05ba5373d",
   "metadata": {},
   "source": [
    "## XGBoost with Bayesian Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6255ff39-79af-4ddd-8504-34bb25a0b39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5912   \u001b[0m | \u001b[0m0.649    \u001b[0m | \u001b[0m0.2938   \u001b[0m | \u001b[0m7.808    \u001b[0m | \u001b[0m1.758    \u001b[0m | \u001b[0m1.517    \u001b[0m | \u001b[0m0.7357   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.6388   \u001b[0m | \u001b[95m0.7887   \u001b[0m | \u001b[95m0.1511   \u001b[0m | \u001b[95m9.613    \u001b[0m | \u001b[95m1.029    \u001b[0m | \u001b[95m9.394    \u001b[0m | \u001b[95m0.5657   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.5025   \u001b[0m | \u001b[0m0.5287   \u001b[0m | \u001b[0m0.01317  \u001b[0m | \u001b[0m8.479    \u001b[0m | \u001b[0m1.653    \u001b[0m | \u001b[0m0.6026   \u001b[0m | \u001b[0m0.9172   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.6103   \u001b[0m | \u001b[0m0.6153   \u001b[0m | \u001b[0m0.2624   \u001b[0m | \u001b[0m9.786    \u001b[0m | \u001b[0m3.885    \u001b[0m | \u001b[0m8.559    \u001b[0m | \u001b[0m0.8429   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.6003   \u001b[0m | \u001b[0m0.558    \u001b[0m | \u001b[0m0.08555  \u001b[0m | \u001b[0m7.795    \u001b[0m | \u001b[0m9.084    \u001b[0m | \u001b[0m4.084    \u001b[0m | \u001b[0m0.6678   \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.6883   \u001b[0m | \u001b[95m0.9983   \u001b[0m | \u001b[95m0.08073  \u001b[0m | \u001b[95m4.694    \u001b[0m | \u001b[95m5.457    \u001b[0m | \u001b[95m0.7922   \u001b[0m | \u001b[95m0.9236   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.5672   \u001b[0m | \u001b[0m0.9319   \u001b[0m | \u001b[0m0.07101  \u001b[0m | \u001b[0m4.354    \u001b[0m | \u001b[0m6.049    \u001b[0m | \u001b[0m0.6404   \u001b[0m | \u001b[0m0.8695   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.6161   \u001b[0m | \u001b[0m0.7977   \u001b[0m | \u001b[0m0.1458   \u001b[0m | \u001b[0m8.315    \u001b[0m | \u001b[0m8.113    \u001b[0m | \u001b[0m9.771    \u001b[0m | \u001b[0m0.5135   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.6076   \u001b[0m | \u001b[0m0.5763   \u001b[0m | \u001b[0m0.2245   \u001b[0m | \u001b[0m5.781    \u001b[0m | \u001b[0m6.359    \u001b[0m | \u001b[0m7.332    \u001b[0m | \u001b[0m0.9828   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.6437   \u001b[0m | \u001b[0m0.9089   \u001b[0m | \u001b[0m0.07678  \u001b[0m | \u001b[0m5.44     \u001b[0m | \u001b[0m8.286    \u001b[0m | \u001b[0m8.674    \u001b[0m | \u001b[0m0.769    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.6107   \u001b[0m | \u001b[0m0.6317   \u001b[0m | \u001b[0m0.1105   \u001b[0m | \u001b[0m7.923    \u001b[0m | \u001b[0m9.649    \u001b[0m | \u001b[0m4.211    \u001b[0m | \u001b[0m0.7537   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.6383   \u001b[0m | \u001b[0m0.7525   \u001b[0m | \u001b[0m0.1266   \u001b[0m | \u001b[0m4.865    \u001b[0m | \u001b[0m9.663    \u001b[0m | \u001b[0m6.212    \u001b[0m | \u001b[0m0.8145   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.6103   \u001b[0m | \u001b[0m0.9767   \u001b[0m | \u001b[0m0.1657   \u001b[0m | \u001b[0m5.749    \u001b[0m | \u001b[0m7.284    \u001b[0m | \u001b[0m8.679    \u001b[0m | \u001b[0m0.6032   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.6531   \u001b[0m | \u001b[0m0.8112   \u001b[0m | \u001b[0m0.08509  \u001b[0m | \u001b[0m8.368    \u001b[0m | \u001b[0m4.147    \u001b[0m | \u001b[0m7.027    \u001b[0m | \u001b[0m0.6716   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.626    \u001b[0m | \u001b[0m0.9203   \u001b[0m | \u001b[0m0.2965   \u001b[0m | \u001b[0m4.928    \u001b[0m | \u001b[0m3.688    \u001b[0m | \u001b[0m6.429    \u001b[0m | \u001b[0m0.9988   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.6341   \u001b[0m | \u001b[0m0.8124   \u001b[0m | \u001b[0m0.1812   \u001b[0m | \u001b[0m3.708    \u001b[0m | \u001b[0m5.571    \u001b[0m | \u001b[0m7.731    \u001b[0m | \u001b[0m0.7155   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.6129   \u001b[0m | \u001b[0m0.6067   \u001b[0m | \u001b[0m0.06122  \u001b[0m | \u001b[0m9.076    \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m8.209    \u001b[0m | \u001b[0m0.9769   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.5651   \u001b[0m | \u001b[0m0.7827   \u001b[0m | \u001b[0m0.2265   \u001b[0m | \u001b[0m6.226    \u001b[0m | \u001b[0m9.542    \u001b[0m | \u001b[0m1.865    \u001b[0m | \u001b[0m0.8101   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.619    \u001b[0m | \u001b[0m0.5993   \u001b[0m | \u001b[0m0.1052   \u001b[0m | \u001b[0m7.658    \u001b[0m | \u001b[0m8.272    \u001b[0m | \u001b[0m7.414    \u001b[0m | \u001b[0m0.5797   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.6482   \u001b[0m | \u001b[0m0.9489   \u001b[0m | \u001b[0m0.08953  \u001b[0m | \u001b[0m7.114    \u001b[0m | \u001b[0m0.1409   \u001b[0m | \u001b[0m6.253    \u001b[0m | \u001b[0m0.7064   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.6503   \u001b[0m | \u001b[0m0.6614   \u001b[0m | \u001b[0m0.09936  \u001b[0m | \u001b[0m9.646    \u001b[0m | \u001b[0m5.225    \u001b[0m | \u001b[0m7.579    \u001b[0m | \u001b[0m0.6223   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.6535   \u001b[0m | \u001b[0m0.9737   \u001b[0m | \u001b[0m0.1926   \u001b[0m | \u001b[0m3.795    \u001b[0m | \u001b[0m1.12     \u001b[0m | \u001b[0m7.704    \u001b[0m | \u001b[0m0.9246   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.6507   \u001b[0m | \u001b[0m0.6004   \u001b[0m | \u001b[0m0.08295  \u001b[0m | \u001b[0m3.864    \u001b[0m | \u001b[0m4.386    \u001b[0m | \u001b[0m3.595    \u001b[0m | \u001b[0m0.7825   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.6831   \u001b[0m | \u001b[0m0.9473   \u001b[0m | \u001b[0m0.1868   \u001b[0m | \u001b[0m5.169    \u001b[0m | \u001b[0m5.079    \u001b[0m | \u001b[0m1.583    \u001b[0m | \u001b[0m0.6201   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.6459   \u001b[0m | \u001b[0m0.8799   \u001b[0m | \u001b[0m0.125    \u001b[0m | \u001b[0m6.939    \u001b[0m | \u001b[0m7.154    \u001b[0m | \u001b[0m9.431    \u001b[0m | \u001b[0m0.8782   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.6785   \u001b[0m | \u001b[0m0.7955   \u001b[0m | \u001b[0m0.05636  \u001b[0m | \u001b[0m9.521    \u001b[0m | \u001b[0m6.634    \u001b[0m | \u001b[0m6.754    \u001b[0m | \u001b[0m0.9561   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.5507   \u001b[0m | \u001b[0m0.7382   \u001b[0m | \u001b[0m0.01391  \u001b[0m | \u001b[0m3.969    \u001b[0m | \u001b[0m6.268    \u001b[0m | \u001b[0m4.338    \u001b[0m | \u001b[0m0.5833   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.6431   \u001b[0m | \u001b[0m0.8355   \u001b[0m | \u001b[0m0.1986   \u001b[0m | \u001b[0m7.707    \u001b[0m | \u001b[0m0.8783   \u001b[0m | \u001b[0m1.661    \u001b[0m | \u001b[0m0.9345   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.6637   \u001b[0m | \u001b[0m0.7045   \u001b[0m | \u001b[0m0.1781   \u001b[0m | \u001b[0m4.913    \u001b[0m | \u001b[0m9.637    \u001b[0m | \u001b[0m6.243    \u001b[0m | \u001b[0m0.823    \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.5621   \u001b[0m | \u001b[0m0.8386   \u001b[0m | \u001b[0m0.2979   \u001b[0m | \u001b[0m9.291    \u001b[0m | \u001b[0m6.685    \u001b[0m | \u001b[0m6.717    \u001b[0m | \u001b[0m0.877    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.6047   \u001b[0m | \u001b[0m0.8283   \u001b[0m | \u001b[0m0.1646   \u001b[0m | \u001b[0m6.995    \u001b[0m | \u001b[0m7.303    \u001b[0m | \u001b[0m9.541    \u001b[0m | \u001b[0m0.9427   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.6471   \u001b[0m | \u001b[0m0.6057   \u001b[0m | \u001b[0m0.1962   \u001b[0m | \u001b[0m7.637    \u001b[0m | \u001b[0m9.439    \u001b[0m | \u001b[0m7.298    \u001b[0m | \u001b[0m0.7657   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.6513   \u001b[0m | \u001b[0m0.636    \u001b[0m | \u001b[0m0.09789  \u001b[0m | \u001b[0m9.634    \u001b[0m | \u001b[0m5.389    \u001b[0m | \u001b[0m7.54     \u001b[0m | \u001b[0m0.6422   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.6301   \u001b[0m | \u001b[0m0.9872   \u001b[0m | \u001b[0m0.1877   \u001b[0m | \u001b[0m3.637    \u001b[0m | \u001b[0m8.2      \u001b[0m | \u001b[0m3.919    \u001b[0m | \u001b[0m0.6254   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.6543   \u001b[0m | \u001b[0m0.5679   \u001b[0m | \u001b[0m0.1138   \u001b[0m | \u001b[0m4.803    \u001b[0m | \u001b[0m3.255    \u001b[0m | \u001b[0m5.215    \u001b[0m | \u001b[0m0.9901   \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.6589   \u001b[0m | \u001b[0m0.8862   \u001b[0m | \u001b[0m0.2373   \u001b[0m | \u001b[0m4.948    \u001b[0m | \u001b[0m9.607    \u001b[0m | \u001b[0m6.282    \u001b[0m | \u001b[0m0.9023   \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.5659   \u001b[0m | \u001b[0m0.8492   \u001b[0m | \u001b[0m0.01092  \u001b[0m | \u001b[0m5.234    \u001b[0m | \u001b[0m5.929    \u001b[0m | \u001b[0m0.4742   \u001b[0m | \u001b[0m0.8906   \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.6845   \u001b[0m | \u001b[0m0.8647   \u001b[0m | \u001b[0m0.05182  \u001b[0m | \u001b[0m3.443    \u001b[0m | \u001b[0m9.674    \u001b[0m | \u001b[0m2.912    \u001b[0m | \u001b[0m0.5771   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.6677   \u001b[0m | \u001b[0m0.896    \u001b[0m | \u001b[0m0.09858  \u001b[0m | \u001b[0m3.489    \u001b[0m | \u001b[0m9.782    \u001b[0m | \u001b[0m3.081    \u001b[0m | \u001b[0m0.5555   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.6416   \u001b[0m | \u001b[0m0.7385   \u001b[0m | \u001b[0m0.08697  \u001b[0m | \u001b[0m5.078    \u001b[0m | \u001b[0m9.682    \u001b[0m | \u001b[0m6.482    \u001b[0m | \u001b[0m0.955    \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.6334   \u001b[0m | \u001b[0m0.74     \u001b[0m | \u001b[0m0.04614  \u001b[0m | \u001b[0m6.528    \u001b[0m | \u001b[0m1.353    \u001b[0m | \u001b[0m4.207    \u001b[0m | \u001b[0m0.8117   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.6741   \u001b[0m | \u001b[0m0.8309   \u001b[0m | \u001b[0m0.04351  \u001b[0m | \u001b[0m4.393    \u001b[0m | \u001b[0m5.74     \u001b[0m | \u001b[0m3.334    \u001b[0m | \u001b[0m0.8011   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.6187   \u001b[0m | \u001b[0m0.6597   \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m5.051    \u001b[0m | \u001b[0m9.493    \u001b[0m | \u001b[0m6.289    \u001b[0m | \u001b[0m0.8645   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.6644   \u001b[0m | \u001b[0m0.7452   \u001b[0m | \u001b[0m0.1111   \u001b[0m | \u001b[0m5.147    \u001b[0m | \u001b[0m5.222    \u001b[0m | \u001b[0m1.577    \u001b[0m | \u001b[0m0.6602   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.6446   \u001b[0m | \u001b[0m0.6375   \u001b[0m | \u001b[0m0.07299  \u001b[0m | \u001b[0m6.161    \u001b[0m | \u001b[0m2.243    \u001b[0m | \u001b[0m3.94     \u001b[0m | \u001b[0m0.5938   \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.6269   \u001b[0m | \u001b[0m0.9964   \u001b[0m | \u001b[0m0.1675   \u001b[0m | \u001b[0m4.336    \u001b[0m | \u001b[0m5.775    \u001b[0m | \u001b[0m3.362    \u001b[0m | \u001b[0m0.9306   \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.5601   \u001b[0m | \u001b[0m0.546    \u001b[0m | \u001b[0m0.02694  \u001b[0m | \u001b[0m4.187    \u001b[0m | \u001b[0m5.537    \u001b[0m | \u001b[0m4.342    \u001b[0m | \u001b[0m0.9624   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.5887   \u001b[0m | \u001b[0m0.7214   \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m4.915    \u001b[0m | \u001b[0m9.782    \u001b[0m | \u001b[0m6.364    \u001b[0m | \u001b[0m0.8648   \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.6083   \u001b[0m | \u001b[0m0.8234   \u001b[0m | \u001b[0m0.0148   \u001b[0m | \u001b[0m3.478    \u001b[0m | \u001b[0m9.664    \u001b[0m | \u001b[0m2.993    \u001b[0m | \u001b[0m0.8085   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.6313   \u001b[0m | \u001b[0m0.9713   \u001b[0m | \u001b[0m0.2585   \u001b[0m | \u001b[0m5.083    \u001b[0m | \u001b[0m5.025    \u001b[0m | \u001b[0m1.698    \u001b[0m | \u001b[0m0.6775   \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.6017   \u001b[0m | \u001b[0m0.8376   \u001b[0m | \u001b[0m0.135    \u001b[0m | \u001b[0m3.452    \u001b[0m | \u001b[0m3.681    \u001b[0m | \u001b[0m1.523    \u001b[0m | \u001b[0m0.9413   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.6405   \u001b[0m | \u001b[0m0.9334   \u001b[0m | \u001b[0m0.0393   \u001b[0m | \u001b[0m8.33     \u001b[0m | \u001b[0m6.676    \u001b[0m | \u001b[0m3.214    \u001b[0m | \u001b[0m0.8571   \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.6482   \u001b[0m | \u001b[0m0.6536   \u001b[0m | \u001b[0m0.1915   \u001b[0m | \u001b[0m5.051    \u001b[0m | \u001b[0m9.658    \u001b[0m | \u001b[0m6.538    \u001b[0m | \u001b[0m0.9641   \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m0.6221   \u001b[0m | \u001b[0m0.965    \u001b[0m | \u001b[0m0.03299  \u001b[0m | \u001b[0m4.213    \u001b[0m | \u001b[0m5.842    \u001b[0m | \u001b[0m5.882    \u001b[0m | \u001b[0m0.7323   \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.6483   \u001b[0m | \u001b[0m0.963    \u001b[0m | \u001b[0m0.1703   \u001b[0m | \u001b[0m3.644    \u001b[0m | \u001b[0m9.572    \u001b[0m | \u001b[0m3.138    \u001b[0m | \u001b[0m0.5278   \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "#optimizes rmse for our linear model\n",
    "def xgb_objective_function(learning_rate,max_depth,subsample,colsample_bytree,reg_lambda,reg_alpha):\n",
    "    # instantiating xgbregressor\n",
    "    xgb = XGBRegressor(objective='reg:squarederror',\n",
    "                       learning_rate=learning_rate, \n",
    "                       max_depth=int(max_depth), \n",
    "                       subsample=subsample, \n",
    "                       colsample_bytree=colsample_bytree,\n",
    "                       reg_lambda=reg_lambda, \n",
    "                       reg_alpha=reg_alpha)\n",
    "\n",
    "    # cross validating inside our objective functions avoids overfitting to our individual set of data\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    cv_scores = cross_val_score(xgb, X_train_scaled, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "xgb_bo = BayesianOptimization(f = xgb_objective_function,\n",
    "                                pbounds = {'learning_rate':(0.01,0.3),\n",
    "                                           'max_depth':(3,10), \n",
    "                                           'subsample':(0.5,1.0),\n",
    "                                           'colsample_bytree':(0.5,1.0),\n",
    "                                           'reg_lambda':(0.01,10),\n",
    "                                           'reg_alpha':(0.01,10)})\n",
    "\n",
    "xgb_bo.maximize(n_iter=50, init_points=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "999ef848-b2d2-427e-ae4d-5129ec9f5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Parameters for XGBRegressor\n",
      "colsample_bytree: 0.9982992616656767\n",
      "learning_rate: 0.08073118145558139\n",
      "max_depth: 4.693932292067143\n",
      "reg_alpha: 5.457384174235592\n",
      "reg_lambda: 0.7921501767353445\n",
      "subsample: 0.9235536582962283\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal Parameters for XGBRegressor\")\n",
    "for key, value in xgb_bo.max['params'].items():\n",
    "    print(\"{}: {}\".format(key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15e1dea4-44c2-4843-ae10-f445b85866db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Optimized XGBoost:\n",
      "Mean Squared Error: 5635339.8217299655\n",
      "Mean Absolute Error: 3555351.6209016396\n",
      "R-squared: 0.7802599833357848\n"
     ]
    }
   ],
   "source": [
    "# using the best hyperparameters when creating our XGBRegressor object\n",
    "xgb_optimized = XGBRegressor(learning_rate = xgb_bo.max['params']['learning_rate'],\n",
    "                                      max_depth = int(xgb_bo.max['params']['max_depth']),\n",
    "                                      subsample = xgb_bo.max['params']['subsample'],\n",
    "                                      colsample_bytree = xgb_bo.max['params']['colsample_bytree'],\n",
    "                                      reg_lambda = xgb_bo.max['params']['reg_lambda'],\n",
    "                                      reg_alpha = xgb_bo.max['params']['reg_alpha'])\n",
    "xgb_optimized.fit(X_train_scaled,y_train)\n",
    "y_pred = xgb_optimized.predict(X_test_scaled)\n",
    "\n",
    "print('Bayesian Optimized XGBoost:')\n",
    "print_metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5974c8ec-ae13-4edc-a4ae-ca9af3083c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7190084592817823"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross validation using the optimized xgbregressor\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "cv_results = cross_val_score(xgb_optimized, X, y, cv=kf, scoring='r2')\n",
    "np.mean(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f961918-f65f-45df-90fb-3a8ef3807c23",
   "metadata": {},
   "source": [
    "# Best Model\n",
    "Our Bayesian optimized XGBoost and Random Forest Regressor models seemed to be the strongest and were very similar in performance. Probably our XGBoost model is the best way to go. It has lower error and though it had a higher r2 when evaluated using the test set, it performs less well using cross validation on our data as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c3851-e135-4cfa-9383-4fe9877af1d7",
   "metadata": {},
   "source": [
    "# Identifying overvalued and undervalued players"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
