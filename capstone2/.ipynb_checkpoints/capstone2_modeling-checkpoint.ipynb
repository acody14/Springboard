{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4a1fde-e01a-46b1-a9ab-a4c2607306f0",
   "metadata": {},
   "source": [
    "# Capstone 2 Modeling\n",
    "## NBA Salary Predictor and Trade Suggestion\n",
    "## Austin Cody\n",
    "#### Models to attempt: Linear Regression, Random Forest Regressor, XGBoost, Support Vector Machine\n",
    "#### Tuning techniques: RandomsearchCV, Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b491875f-4ca7-4a0a-8add-5fcb198f370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31a9f4b6-a9c8-450e-8cfa-eb76b6aa50e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining functions\n",
    "def print_metrics(y_test,y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f'Mean Squared Error: {rmse}')\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52dbbe31-72a1-4c8c-8ab6-f1f8bdc1d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in csv, splitting data into train/test\n",
    "df = pd.read_csv('nba_salaries_dummies.csv')\n",
    "features = ['age','2_pointers_pg','3_pointers_pg','free_throws_pg','assists_pg','points_pg', 'minutes_pg']\n",
    "\n",
    "X = df[features].values\n",
    "y = df['salary'].values\n",
    "\n",
    "# we don't need to stratify because this data is necessarily balanced\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec0412bd-92a6-47c5-9785-cdd4d7a50573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling from previous notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b28f8e-22d5-4f79-9313-b3fcc442bfb0",
   "metadata": {},
   "source": [
    "## Linear Regression using Lasso Regularization and hyperparameter tuning using Bayesian Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "548e4c7a-3d62-482c-8ff1-dcb3ae51606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "#optimizes rmse for our linear model\n",
    "def lasso_eval(alpha):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    y_pred = lasso.predict(X_test_scaled)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return -rmse # we want to minimize rmse so we make it negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11d572f2-eb82-411a-b29c-9c6b059562e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |\n",
      "-------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-7.007e+0\u001b[0m | \u001b[0m0.5351   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-7.007e+0\u001b[0m | \u001b[95m0.743    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-7.007e+0\u001b[0m | \u001b[0m0.52     \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-7.007e+0\u001b[0m | \u001b[0m0.4516   \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-7.007e+0\u001b[0m | \u001b[95m0.8288   \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m-7.007e+0\u001b[0m | \u001b[95m1.0      \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austincody/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.014e+15, tolerance: 3.308e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/austincody/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.014e+15, tolerance: 3.308e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/austincody/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.014e+15, tolerance: 3.308e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/austincody/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.014e+15, tolerance: 3.308e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/austincody/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.013e+15, tolerance: 3.308e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/austincody/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.013e+15, tolerance: 3.308e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/austincody/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.013e+15, tolerance: 3.308e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "ename": "NotUniqueError",
     "evalue": "Data point [1.] is not unique. You can set \"allow_duplicate_points=True\" to avoid this error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotUniqueError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m lasso_bo \u001b[38;5;241m=\u001b[39m BayesianOptimization(f \u001b[38;5;241m=\u001b[39m lasso_eval,\n\u001b[1;32m      2\u001b[0m                                 pbounds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)})\n\u001b[0;32m----> 4\u001b[0m lasso_bo\u001b[38;5;241m.\u001b[39mmaximize(n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, \n\u001b[1;32m      5\u001b[0m                   init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bayes_opt/bayesian_optimization.py:310\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[1;32m    309\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bayes_opt/bayesian_optimization.py:208\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mprobe(params)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bayes_opt/target_space.py:239\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    236\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m target\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bayes_opt/target_space.py:196\u001b[0m, in \u001b[0;36mTargetSpace.register\u001b[0;34m(self, params, target, constraint_value)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColours\u001b[38;5;241m.\u001b[39mRED\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mData point \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not unique. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_duplicate_points\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m duplicates registered.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    194\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Continuing ...\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColours\u001b[38;5;241m.\u001b[39mEND\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotUniqueError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData point \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not unique. You can set \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_duplicate_points=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    197\u001b[0m                              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavoid this error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params, x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target, [target]])\n",
      "\u001b[0;31mNotUniqueError\u001b[0m: Data point [1.] is not unique. You can set \"allow_duplicate_points=True\" to avoid this error"
     ]
    }
   ],
   "source": [
    "lasso_bo = BayesianOptimization(f = lasso_eval,\n",
    "                                pbounds = {'alpha': (0.01, 1.0)})\n",
    "\n",
    "lasso_bo.maximize(n_iter=150, \n",
    "                  init_points=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af0af3d-238e-4197-a176-169542301937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### K FOLD CROSS VALIDATION ON YOUR DATA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
